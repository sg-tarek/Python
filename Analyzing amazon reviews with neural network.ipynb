{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXvIdATVxb6q"
   },
   "source": [
    "#Amaxon Luxury Product Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8TsrdcnyCK1"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "23kcYKtHg0Jf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RcEdR1fzvJZR"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/DanishDahaka/dsba_winter2020/master/Project/Luxury_Beauty/Preprocessing/Data/hair.csv?token=AQ2RLFJLCBUCFPTJLWFE3WK7Y2FBM\", )\n",
    "df = df.drop(\"cluster\", axis=1)\n",
    "df = df.drop_duplicates(subset=[\"text_generation_preprocessed\"])\n",
    "df['target_sentiment_binary'] = df.target_sentiment_binary.map({'negative' : 0, 'positive' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1JzA2eqikMu",
    "outputId": "46c0f778-9149-4cbe-8def-34201b238d7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68368, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XElDQzB2shBA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text_generation_preprocessed</th>\n",
       "      <th>text_preprocessed_for_sentiment</th>\n",
       "      <th>target_sentiment_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>34729</td>\n",
       "      <td>this is my favorite hand cream. it is not grea...</td>\n",
       "      <td>['favorit', 'hand', 'cream', 'greasi', 'nice',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35638</td>\n",
       "      <td>best hand cream ever. one at work, one in my p...</td>\n",
       "      <td>['best', 'hand', 'cream', 'work', 'purs', 'nig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44680</td>\n",
       "      <td>keep this by my kitchen sink. after every wash...</td>\n",
       "      <td>['kitchen', 'sink', 'wash', 'add', 'hand', 'lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>44745</td>\n",
       "      <td>find this soap to be gentle and quite excellen...</td>\n",
       "      <td>['soap', 'gentl', 'excel', 'qualityfin', 'soap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>45096</td>\n",
       "      <td>love this hand cream. work in job where am con...</td>\n",
       "      <td>['love', 'hand', 'cream', 'work', 'job', 'cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       text_generation_preprocessed  \\\n",
       "0       34729  this is my favorite hand cream. it is not grea...   \n",
       "2       35638  best hand cream ever. one at work, one in my p...   \n",
       "4       44680  keep this by my kitchen sink. after every wash...   \n",
       "5       44745  find this soap to be gentle and quite excellen...   \n",
       "6       45096  love this hand cream. work in job where am con...   \n",
       "\n",
       "                     text_preprocessed_for_sentiment  target_sentiment_binary  \n",
       "0  ['favorit', 'hand', 'cream', 'greasi', 'nice',...                        1  \n",
       "2  ['best', 'hand', 'cream', 'work', 'purs', 'nig...                        1  \n",
       "4  ['kitchen', 'sink', 'wash', 'add', 'hand', 'lo...                        1  \n",
       "5  ['soap', 'gentl', 'excel', 'qualityfin', 'soap...                        1  \n",
       "6  ['love', 'hand', 'cream', 'work', 'job', 'cons...                        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68368, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOLwAwIITYJJ"
   },
   "source": [
    "## Word Embedding (Tf-idf) - Trinomial target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "orpOCW30TXdv"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['text_preprocessed_for_sentiment'])\n",
    "\n",
    "y = df[\"target_sentiment_binary\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DPXDw5JIoSM-"
   },
   "outputs": [],
   "source": [
    "## split dataset (Binomial target)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=df['target_sentiment_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IKnKHFJ5RkVZ"
   },
   "outputs": [],
   "source": [
    "#From sparse to dense data\n",
    "X_test_A = X_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SKWHNnJVszCE"
   },
   "outputs": [],
   "source": [
    "#From sparse to dense data\n",
    "X_train_A = X_train.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJnEMH7NJpCp"
   },
   "source": [
    "Motivation for function: https://stackoverflow.com/questions/41538692/using-sparse-matrices-with-keras-and-tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq5hEZszzlwf"
   },
   "source": [
    "## Neural Network (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ciHzVarozZgi"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d078bf5335da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m \u001b[0;31m#Our model type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m \u001b[0;31m#Type of layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Sequential #Our model type\n",
    "from keras.layers import Dense #Type of layer\n",
    "\n",
    "#Combining Keras with Sklearn (enables us to do K-fold crossvalidation and things like that - not a necessary package)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxNx4N2ez17y"
   },
   "outputs": [],
   "source": [
    "#When working with neural network, we will need a column for each target output. \n",
    "#Given that we have three penguin species, we will need three columns with dummy variables. \n",
    "#We can create dummies by using the np_utils, which does the same as the one hot encoder from sklearn:\n",
    "\n",
    "dummy_y_train = to_categorical(y_train)\n",
    "dummy_y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5H1IQkUWq4PE"
   },
   "source": [
    "Motivation for function: https://stackoverflow.com/questions/41538692/using-sparse-matrices-with-keras-and-tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRkc1hv7q0c9"
   },
   "outputs": [],
   "source": [
    "#Keras NN model cannot handle sparse matrix directly. \n",
    "#The data has to be dense array or matrix, \n",
    "#but transforming the whole training data to dense array wonâ€™t fit into my RAM. \n",
    "#So I had to define a function, which generates iterable generator object, \n",
    "#so that it can be fed to NN model.\n",
    "def batch_generator(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size #steps_per_epoch\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].todense()\n",
    "        y_batch = y_data[index_batch]\n",
    "        counter += 1\n",
    "        yield np.array(X_batch),y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXQUAt8oLBiS"
   },
   "source": [
    "Dokumentation for EarlyStopping: https://keras.io/api/callbacks/early_stopping/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8nbEx0QESiJ"
   },
   "outputs": [],
   "source": [
    "n_cols = X_train.shape[1]\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2, monitor='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQEaReUcGdVy"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qq0qrxaMlNrj"
   },
   "source": [
    "fit_generator documentation: \n",
    "\n",
    "https://www.kite.com/python/docs/keras.Model.fit_generator\n",
    "\n",
    "https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42genH-KHd5i",
    "outputId": "2eb5cb7e-14ec-4e30-c0a6-503486b18af9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax')) \n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(batch_generator(X_train, dummy_y_train, 20),\n",
    "                    epochs = 20,\n",
    "                    verbose=1,\n",
    "                    steps_per_epoch = X_train.shape[1]/20, #Very important so it doesent run forever\n",
    "                    callbacks = [early_stopping_monitor]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yi9cqBwYHarD",
    "outputId": "648118ca-7969-4dc5-c6ea-047024805add"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8dxfnU-aCPS"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('ann_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncJLRcVHrpui"
   },
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model = load_model('ann_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "-02dH0qRFfzZ",
    "outputId": "45907abb-5fd1-4dc0-cf6f-cb27994db644"
   },
   "outputs": [],
   "source": [
    "#Summarize history for accuracy (Binomial model)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z76Dr7p069k1"
   },
   "source": [
    "Evaluation documentation: https://keras.io/api/models/model_training_apis/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "380GMSx0KFLO",
    "outputId": "07388d2a-3d9b-4f91-f920-1ad06750dce8"
   },
   "outputs": [],
   "source": [
    "#Evaluation of Binomial model\n",
    "model.evaluate(X_test_A, dummy_y_test, steps=10, verbose=1, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJBnUeUHMZKy"
   },
   "source": [
    "###Evaluation of Binomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxbWhtNBMYYf"
   },
   "outputs": [],
   "source": [
    "## encode y\n",
    "dic_y_mapping = {n:label for n,label in \n",
    "                 enumerate(np.unique(y_test))}\n",
    "inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n",
    "y_test = np.array([inverse_dic[y] for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKm59lt2aSbu"
   },
   "outputs": [],
   "source": [
    "## test\n",
    "predicted_prob = model.predict(X_test_A)\n",
    "predicted = [dic_y_mapping[np.argmax(pred)] for pred in \n",
    "             predicted_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "HNx9g7T0aoaz",
    "outputId": "1cce3907-b5e0-471a-85ed-62828a8ec904"
   },
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cf_matrix_bi = confusion_matrix(y_test, predicted)\n",
    "\n",
    "#Lets look at it graphically:\n",
    "group_names = [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix_bi.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix_bi.flatten() / np.sum(cf_matrix_bi)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cf_matrix_bi, annot=labels, fmt=\"\", cmap=\"Blues\")\n",
    "labels = ['Negative', 'Positive']\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_xlabel('Predicted data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_A, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#Roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred[:,1])\n",
    "\n",
    "#AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=[7, 6])\n",
    "plt.plot(fpr, tpr, label=\"ANN Neural Network (AUC={:0.2f})\".format(roc_auc), linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"green\", linestyle=\"--\", label=\"Random (AUC=0.50)\")\n",
    "plt.xlabel(\"FPR\", fontsize=13)\n",
    "plt.ylabel(\"TPR\", fontsize=13)\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIQhBbH_qmzk"
   },
   "source": [
    "## ANN Sklearn (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8NrVoke0Exp"
   },
   "source": [
    "Dokumentation for MLP: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=mlp#sklearn.neural_network.MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zn6iVtk2Mwjf"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_bi = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 2), #100 neurons and 2 layers\n",
    "    activation=\"relu\", #For the hidden layers\n",
    "    solver='adam',\n",
    "    batch_size=200,\n",
    "    max_iter=5, #Number of epochs\n",
    "    verbose=True, #Print progess\n",
    "    early_stopping=True, #terminate training when validation score is not improving\n",
    "    n_iter_no_change=2, #Maximum number of epochs to not meet tol improvement.\n",
    "    validation_fraction=0.1, #default\n",
    "    random_state=42 \n",
    ")\n",
    "\n",
    "mlp_bi.out_activation_ = 'logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nj9cQZZ0NMy1",
    "outputId": "8026a6eb-1b2f-41ce-d407-3774dd3b614a"
   },
   "outputs": [],
   "source": [
    "mlp_bi.fit(X_train_A, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "romNzTcqhvId",
    "outputId": "6d824550-87a7-44fd-f269-ec696f7a8949"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"Negative\", \"Positive\"]\n",
    "print(classification_report(y_train, mlp_bi.predict(X_train_A), target_names=labels))\n",
    "print(classification_report(y_test, mlp_bi.predict(X_test_A), target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "PjfTHpmHpfcn",
    "outputId": "5420d3b4-35cf-4a11-d33d-30de50816f70"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#Roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, mlp_bi.predict_proba(X_test)[:,1])\n",
    "\n",
    "#AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=[7, 6])\n",
    "plt.plot(fpr, tpr, label=\"MLP Neural Network (AUC={:0.2f})\".format(roc_auc), linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"green\", linestyle=\"--\", label=\"Random (AUC=0.50)\")\n",
    "plt.xlabel(\"FPR\", fontsize=13)\n",
    "plt.ylabel(\"TPR\", fontsize=13)\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "6RaRwrgPs4ru",
    "outputId": "8d9fab3c-2543-4773-f479-fd3e029222d3"
   },
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, mlp_bi.predict(X_test))\n",
    "\n",
    "#Lets look at it graphically:\n",
    "group_names = [\"TN\", \"FP\", \"FN\", \"TP\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap=\"Blues\")\n",
    "labels = ['Negative', 'Positive']\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_xlabel('Predicted data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MFxmkGA_H1o"
   },
   "source": [
    "Inspiration for pickle: https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o37XU6Og3yho",
    "outputId": "aed253a2-34e5-48bf-e3ac-537eda070ff8"
   },
   "outputs": [],
   "source": [
    "!pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JI7Ah_D-nud"
   },
   "outputs": [],
   "source": [
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqYwL7R6-se9"
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "#filename = 'mlp_model_bi.sav'\n",
    "#pickle.dump(mlp_bi, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbuWk5fd-0es"
   },
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ANN_and_MLP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "214.184px",
    "left": "959.133px",
    "top": "125.056px",
    "width": "279.757px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
